# Trilobot Project Analysis and Improvement Plan
Trilobot is an AI-powered robot platform built on a Raspberry Pi 4, using a PS4 controller, Flask web interface, camera module, and various onboard sensors and LEDs. 
The 2025 upgrade focuses on enhancing interactivity with voice control (using ElevenLabs for TTS), improving control system robustness, and potentially re-introducing computer vision if dependencies can be managed.

## Current Specifications

### Hardware
- Raspberry Pi 4
- Pimoroni Trilobot robot platform
- Raspberry Pi Camera Module (HQ assumed, based on imx477 sensor)
- PS4 Wireless Controller
- Onboard Distance Sensor
- Onboard Addressable RGB LEDs & Button LEDs

### Software (Current State - April 11, 2025)
- Python 3.11 (via venv)
- Flask web server
- Picamera2 for camera streaming
- Evdev for PS4 controller input
- Modular Python code (`main.py`, `control_manager.py`, `camera_processor.py`, `ps4_controller.py`, `voice_controller.py`, `web_control.py`, `config.py`, `debugging.py`)
- Configuration via `config.json`
- Logging to console and timestamped files in `logs/` directory
- Basic state tracking (`debugging.py`)

### Current Features
1. **Dual Control Systems**:
   - PS4 controller support (connection established, input processing under debug)
   - Web interface control (movement confirmed working)

2. **Movement Control**:
   - Basic forward/backward/turn/stop actions via `ControlManager`.
   - Speed control via `config.json`.
   - Emergency stop function (basic implementation).

3. **Visual Feedback**:
   - Live camera streaming to web browser (currently experiencing issues after initial load).
   - Basic camera overlay modes (normal, night_vision, targeting - functionality requires review).

4. **LED Effects**:
   - Knight Rider scanning effect (code exists, triggered by web/PS4).
   - Party mode with color cycling (code exists, triggered by web/PS4).
   - Button LED control (basic toggle via web).

5. **Sensor Integration**:
   - Distance sensor (hardware present, but not actively used in current control logic).

6. **Voice Output (TTS)**:
   - ElevenLabs integration for TTS (code implemented).
   - Caching system for TTS responses.
   - Startup announcement implemented.
   - *Blocked by missing Python modules.*

## Current Limitations & Issues (As of April 11, 2025)

1. **PS4 Controller Input:** While connection is successful, controller actions (buttons, sticks) are not reliably triggering robot movement or actions. (Debugging in progress)
2. **Camera Stream Stability:** The MJPEG stream works initially but stops displaying in the web interface after some time. (Debugging in progress)
3. **Voice System Inactive:** Required Python modules (`SpeechRecognition`, `PyAudio`, `elevenlabs`) are not installed/detected in the venv, preventing TTS and voice recognition from functioning.
4. **Control Mode Management:** Removed explicit mode setting from web controls, needs verification that PS4 retains control correctly.
5. **Web Button Mapping:** Web interface buttons trigger specific LED effects, not direct PS4 button equivalents.
6. **Computer Vision Removed:** OpenCV and related features were removed due to installation/dependency issues on the Pi.

## Revised Plan & Next Steps

**Overall Goal:** Stabilize core features (PS4 control, camera stream) and enable voice output.

**Phase 1: Stabilize Core Systems (Current Focus)**

1.  **Fix PS4 Controller Input:**
    *   **Action:** Analyze logs with DEBUG level enabled (generated from previous steps).
    *   **Goal:** Identify why `ps4_controller.py` isn't translating stick/button events into `control_manager.execute_action` calls when mode is PS4.
    *   **Potential Fixes:** Adjust logic in `_process_axis_event`, `_process_button_event`, or `_process_movement` in `ps4_controller.py`.

2.  **Fix Camera Stream:**
    *   **Action:** Analyze logs with DEBUG level enabled.
    *   **Goal:** Determine if the `generate()` loop in `web_control.py` stops running, throws an error, or if the issue is client-side (browser).
    *   **Potential Fixes:** Improve error handling in the loop, check resource usage, potentially simplify frame processing.

3.  **Enable Voice Output:**
    *   **Action (User):** Run `pip install SpeechRecognition PyAudio elevenlabs` within the activated venv on the Pi.
    *   **Goal:** Allow the `voice_controller` module to load correctly and test TTS via the startup announcement.
    *   **Potential Fixes:** Address any pip installation errors.

**Phase 2: Refine and Test**

1.  **Verify Control Modes:** Ensure PS4 controller maintains priority and web controls work alongside it correctly.
2.  **Test Voice System:** Confirm startup announcement plays. Test other `speak()` calls if desired.
3.  **Review LED Effects:** Ensure Knight Rider / Party Mode trigger correctly from both PS4 and web.
4.  **Basic Voice Recognition (Future):** Once TTS works, plan for installing microphone and implementing basic command listening.
5.  **Re-evaluate Computer Vision (Future):** After core stability, decide whether to attempt re-integrating object detection, possibly using alternative libraries or methods if OpenCV remains problematic.

**Removed/Postponed from Original Plan:**

*   Extensive system checks in `run_trilobot.sh` (Simplified).
*   Initial focus on computer vision features (Removed due to dependencies).
*   Advanced Web UI features (WebSocket, mobile design) - Postponed.
*   Autonomous Navigation - Postponed. 